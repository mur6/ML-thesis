# OakInk: A Large-scale Knowledge Repository for Understanding Hand-Object Interaction

人間がオブジェクトを操作する方法を学習するには、マシンが2つの観点から知識を取得する必要があります。1つはオブジェクトのアフォーダンスを理解するためのもので、もう1つはアフォーダンスに基づいて人間の相互作用を学習するためのものです。これらの2つの知識ベースは非常に重要ですが、現在のデータベースにはそれらの包括的な認識が欠けていることがわかります。この作業では、手とオブジェクトの相互作用を視覚的および認知的に理解するために、マルチモーダルで豊富な注釈が付けられた知識リポジトリ、OakInkを提案します。1,800の一般的な家庭用品の収集を開始し、それらのアフォーダンスに注釈を付けて、最初のナレッジベースであるオークを構築します。アフォーダンスを考慮して、オークの100個の選択されたオブジェクトとの豊富な人間の相互作用を記録します。最後に、100個の記録されたオブジェクトの相互作用を、新しい方法であるTinkを介して仮想の対応物に転送します。記録および転送された手とオブジェクトの相互作用は、2番目の知識ベースであるインクを構成します。その結果、OakInkには、50,000の異なるアフォーダンスを意識した、意図指向の手とオブジェクトの相互作用が含まれています。ポーズ推定と把握生成タスクでOakInkのベンチマークを行います。さらに、OakInkの2つの実用的なアプリケーションを提案します。インテントベースのインタラクション生成とハンドオーバー生成です。当社のデータセットとソースコードは、次のURLで公開されています。このhttpsURL。
