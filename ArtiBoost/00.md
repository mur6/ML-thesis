# ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation via Online Exploration and Synthesis

## Abstract
Estimating the articulated 3D hand-object pose from a single RGB image is a highly ambiguous and challenging problem, requiring large-scale datasets that contain diverse hand poses, object types, and camera viewpoints.
単一のRGB画像から関節のある3D手オブジェクトのポーズを推定することは、非常にあいまいで困難な問題であり、さまざまな手のポーズ、オブジェクトタイプ、およびカメラの視点を含む大規模なデータセットが必要です。

Most real-world datasets lack these diversities.
ほとんどの実際のデータセットには、これらの多様性が欠けています。

In contrast, data synthesis can easily ensure those diversities separately.
対照的に、データ合成では、これらの多様性を個別に簡単に確認できます。

However, constructing both valid and diverse hand-object interactions and efficiently learning from the vast synthetic data is still challenging.
ただし、有効で多様な手とオブジェクトの相互作用の両方を構築し、膨大な合成データから効率的に学習することは依然として困難です。

To address the above issues, we propose ArtiBoost, a lightweight online data enhancement method.
上記の問題に対処するために、軽量のオンラインデータ拡張方法であるArtiBoostを提案します。

ArtiBoost can cover diverse hand-object poses and camera viewpoints through sampling in a Composited hand-object Configuration and Viewpoint space (CCV-space) and can adaptively enrich the current hard-discernable items by loss-feedback and sample re-weighting.
ArtiBoostは、合成手オブジェクト構成および視点空間（CCV空間）でサンプリングすることにより、さまざまな手オブジェクトのポーズとカメラの視点をカバーでき、損失フィードバックとサンプルの再重み付けによって、現在の識別が難しいアイテムを適応的に強化できます。

ArtiBoost alternatively performs data exploration and synthesis within a learning pipeline, and those synthetic data are blended into real-world source data for training. We apply ArtiBoost on a simple learning baseline network and witness the performance boost on several hand-object benchmarks.
ArtiBoostは、学習パイプライン内でデータの探索と合成を交互に実行し、それらの合成データはトレーニングのために実際のソースデータにブレンドされます。 ArtiBoostを単純な学習ベースラインネットワークに適用し、いくつかのハンドオブジェクトベンチマークでパフォーマンスが向上するのを目撃します。

Our models and code are available at https://github.com/lixiny/ArtiBoost.
モデルとコードはhttps://github.com/lixiny/ArtiBoostで入手できます。
