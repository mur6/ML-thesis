3 MAML, RAPID LEARNING, AND FEATURE REUSE
Our goal is to understand whether the MAML algorithm efficiently solves new tasks due to rapid learning or feature reuse.
私たちの目標は、MAMLアルゴリズムが、迅速な学習または機能の再利用によって新しいタスクを効率的に解決するかどうかを理解することです。

In rapid learning, large representational and parameter changes occur during adaptation to each new task as a result of favorable weight conditioning from the meta-initialization.
迅速な学習では、メタ初期化からの好ましい重み調整の結果として、新しい各タスクへの適応中に大きな表現とパラメーターの変更が発生します。

In feature reuse, the meta-initialization already contains highly useful features that can mostly be reused as is for new tasks, so little task-specific adaptation occurs. Figure 1 shows a schematic of these two hypotheses.
機能の再利用では、メタ初期化にはすでに非常に便利な機能が含まれており、ほとんどの場合、新しいタスクの場合と同じように再利用できるため、タスク固有の適応はほとんど発生しません。図1に、これら2つの仮説の概略図を示します。

We start off by overviewing the details of the MAML algorithm, and then we study the rapid learning vs feature reuse question via layer freezing experiments and analyzing latent representations of models trained with MAML. The results strongly support feature reuse as the predominant factor behind MAML’s success. In Section 4, we explore the consequences of this, providing a significant simplification of MAML, the ANIL algorithm, and in Section 6, we outline the connections to meta-learning more broadly.
まず、MAMLアルゴリズムの詳細を概説し、次に、レイヤー凍結実験とMAMLでトレーニングされたモデルの潜在表現の分析を通じて、迅速な学習と機能の再利用の質問を研究します。結果は、MAMLの成功の背後にある主要な要因として機能の再利用を強くサポートしています。セクション4では、この結果を調査し、MAML、ANILアルゴリズムを大幅に簡素化し、セクション6では、メタ学習への接続をより広く概説します。

3.1 OVERVIEW OF MAML
The MAML algorithm finds an initialization for a neural network so that new tasks can be learnt with very few examples (k examples from each class for k-shot learning) via two optimization loops:
MAMLアルゴリズムは、ニューラルネットワークの初期化を検出するため、2つの最適化ループを介して非常に少数の例（kショット学習の各クラスからのk個の例）で新しいタスクを学習できます:

• Outer Loop: Updates the initialization of the neural network parameters (often called the meta-initialization) to a setting that enables fast adaptation to new tasks.
•外部ループ：ニューラルネットワークパラメーターの初期化（メタ初期化と呼ばれることが多い）を、新しいタスクへの迅速な適応を可能にする設定に更新します。
• Inner Loop: Performs adaptation: takes the outer loop initialization, and, separately for each task, performs a few gradient updates over the k labelled examples (the support set) provided for adaptation.
•内部ループ：適応を実行します：外部ループの初期化を行い、タスクごとに個別に、適応用に提供されたk個のラベル付きの例（サポートセット）に対していくつかの勾配更新を実行します。

More formally, we first define our base model to be a neural network with meta-initialization parameters θ; let this be represented by fθ. We have have a distribution D over tasks, and draw a batch {T1,...,TB} of B tasks from D. For each task Tb, we have a support set of examples STb, which are used for inner loop updates, and a target set of examples ZTb , which are used for outer loop updates.
Let θ(b) signify θ after i gradient updates for task T , and let θ(b) = θ. In the inner ib0 loop, during each update, we compute
より正式には、最初にベースモデルをメタ初期化パラメーターθを持つニューラルネットワークとして定義します。これをfθで表すとします。タスクに分散Dがあり、DからBタスクのバッチ{T1、...、TB}を描画します。タスクTbごとに、内部ループの更新に使用されるサンプルSTbのサポートセットがあります。および例ZTbのターゲットセット。これらは外部ループの更新に使用されます。
タスクTのi勾配更新後のθ（b）がθを表すとし、θ（b）=θとします。内側のib0ループでは、更新のたびに計算します。

数式(1)

for m fixed across all task, L_ST is the loss on the support set of Tb after m-1 inner loop updates.
We then define the meta-loss as

数式(-)

where LZT is the loss on the target set of Tb after m inner loop updates, making clear the on θ. The outer optimization loop then updates θ as
ここで、LZTは、m個の内部ループが更新された後のTbのターゲットセットの損失であり、onθを明確にします。次に、外側の最適化ループはθを次のように更新します。


At test time, we draw unseen tasks {T1 ,...,Tn } from the task distribution, and evaluate the loss and accuracy on ZT(test) after inner loop adaptation using ST(test) (e.g. loss is 数式)
テスト時に、タスク分布から見えないタスク{T1、...、Tn}を抽出し、ST（test）を使用して内部ループ適応後のZT（test）の損失と精度を評価します（例：損失は X）


3.2 RAPID LEARNING OR FEATURE REUSE?
3.2 迅速な学習または機能の再利用？

We now turn our attention to the key question: Is MAML’s efficacy predominantly due to rapid learning or feature reuse? In investigating this question, there is an important distinction between the head (final layer) of the network and the earlier layers (the body of the network). In each few-shot learning task, there is a different alignment between the output neurons and classes. For instance, in task T1, the (wlog) five output neurons might correspond, in order, to the classes (dog, cat, frog, cupcake, phone), while for a different task, T2, they might correspond, in order, to (airplane, frog, boat, car, pumpkin). This means that the head must necessarily change for each task to learn the new alignment, and for the rapid learning vs feature reuse question, we are primarily interested in the behavior of the body of the network. We return to this in more detail in Section 5, where we present an algorithm (NIL) that does not use a head at test time.
ここで、重要な質問に注意を向けます。MAMLの有効性は、主に迅速な学習または機能の再利用によるものですか。この質問を調査する際に、ネットワークのヘッド（最終層）と初期の層（ネットワークの本体）の間に重要な違いがあります。各数ショットの学習タスクでは、出力ニューロンとクラスの間に異なる配置があります。たとえば、タスクT1では、（wlog）5つの出力ニューロンが順番にクラス（犬、猫、カエル、カップケーキ、電話）に対応し、別のタスクT2では、順番に対応する場合があります。 to（飛行機、カエル、ボート、車、カボチャ）。つまり、新しいアラインメントを学習するには、タスクごとに頭を変更する必要があります。迅速な学習と機能の再利用の質問では、主にネットワーク本体の動作に関心があります。これについては、セクション5で詳しく説明します。ここでは、テスト時にヘッドを使用しないアルゴリズム（NIL）を示します。

To study rapid learning vs feature reuse in the network body, we perform two sets of experiments: (1) We evaluate few-shot learning performance when freezing parameters after MAML training, without test time inner loop adaptation; (2) We use representational similarity tools to directly analyze how much the network features and representations change through the inner loop. We use the MiniImageNet dataset, a popular standard benchmark for few-shot learning, and with the standard convolutional architecture in Finn et al. (2017). Results are averaged over three random seeds. Full implementation details are in Appendix B.
ネットワーク本体での迅速な学習と機能の再利用を研究するために、2セットの実験を実行します。（1）テスト時間の内部ループ適応なしでMAMLトレーニング後にパラメーターを凍結するときの数ショット学習パフォーマンスを評価します。 （2）表現類似性ツールを使用して、ネットワークの機能と表現が内部ループを通じてどの程度変化するかを直接分析します。数ショット学習の一般的な標準ベンチマークであるMiniImageNetデータセットを使用し、Finnetal。の標準畳み込みアーキテクチャを使用します。 （2017）。結果は、3つのランダムシードで平均化されます。完全な実装の詳細は付録Bにあります。

3.2.1 FREEZING LAYER REPRESENTATIONS
To study the impact of the inner loop adaptation, we freeze a contiguous subset of layers of the network, during the inner loop at test time (after using the standard MAML algorithm, incorporating both optimization loops, for training). In particular, the frozen layers are not updated at all to the test time task, and must reuse the features learned by the meta-initialization that the outer loop converges to. We compare the few-shot learning accuracy when freezing to the accuracy when allowing inner loop adaptation.
Results are shown in Table 1. We observe that even when freezing all layers in the network body, performance hardly changes. This suggests that the meta-initialization has already learned good enough features that can be reused as is, without needing to perform any rapid learning for each test time task.
3.2.1層表現の凍結
内部ループ適応の影響を調査するために、テスト時の内部ループ中に（トレーニング用に両方の最適化ループを組み込んだ標準のMAMLアルゴリズムを使用した後）、ネットワークのレイヤーの連続したサブセットをフリーズします。特に、フリーズされたレイヤーはテスト時間タスクに対してまったく更新されないため、外側のループが収束するメタ初期化によって学習された機能を再利用する必要があります。フリーズ時の数ショットの学習精度を、内部ループの適応を許可する場合の精度と比較します。
結果を表1に示します。ネットワーク本体のすべてのレイヤーをフリーズしても、パフォーマンスはほとんど変化しないことがわかります。これは、メタ初期化が、テスト時間タスクごとに迅速な学習を実行する必要なしに、そのまま再利用できる十分な機能をすでに学習していることを示しています。


3.2.2 REPRESENTATIONAL SIMILARITY EXPERIMENTS
3.2.2代表的な類似性実験

We next study how much the latent representations (the latent functions) learned by the neural network change during the inner loop adaptation phase. Following several recent works (Raghu et al., 2017; Saphra and Lopez, 2018; Morcos et al., 2018; Maheswaranathan et al., 2019; Raghu et al., 2019; Gotmare et al., 2018; Bau et al., 2018) we measure this by applying Canonical Correlation Analysis (CCA) to the latent representations of the network. CCA provides a way to the compare representations of two (latent) layers L1 , L2 of a neural network, outputting a similarity score between 0 (not similar at all) and 1 (identical). For full details, see Raghu et al. (2017); Morcos et al. (2018). In our analysis, we take L1 to be a layer before the inner loop adaptation steps, and L2 after the inner loop adaptation steps. We compute CCA similarity between L1, L2, averaging the similarity score across different random seeds of the model and different test time tasks. Full details are in Appendix B.2
次に、ニューラルネットワークによって学習された潜在表現（潜在関数）が、内部ループ適応フェーズ中にどの程度変化するかを調べます。最近のいくつかの研究に続いて（Raghu et al。、2017; Saphra and Lopez、2018; Morcos et al。、2018; Maheswaranathan et al。、2019; Raghu et al。、2019; Gotmare et al。、2018; Bauetal。 、2018）ネットワークの潜在的な表現にCanonical Correlation Analysis（CCA）を適用することにより、これを測定します。 CCAは、ニューラルネットワークの2つの（潜在）層L1、L2の表現を比較する方法を提供し、0（まったく類似していない）と1（同一）の間の類似スコアを出力します。詳細については、Raghuetal。を参照してください。 （2017）; Morcosetal。 （2018）。私たちの分析では、L1を内部ループ適応ステップの前のレイヤーとし、L2を内部ループ適応ステップの後のレイヤーとします。 L1、L2間のCCA類似度を計算し、モデルのさまざまなランダムシードとさまざまなテスト時間タスクの類似度スコアを平均します。詳細は付録B.2にあります。

The result is shown in Figure 2, left pane. Representations in the body of the network (the convo- lutional layers) are highly similar, with CCA similarity scores of > 0.9, indicating that the inner loop induces little to no functional change. By contrast, the head of the network, which does change significantly in the inner loop, has a CCA similarity of less than 0.5. To further validate this, we also compute CKA (Centered Kernel Alignment) (Kornblith et al., 2019) (Figure 2 right), another similarity metric for neural network representations, which illustrates the same pattern. These repre- sentational analysis results strongly support the feature reuse hypothesis, with further results in the Appendix, Sections B.3 and B.4 providing yet more evidence.
結果を図2の左側のペインに示します。ネットワークの本体（畳み込み層）の表現は非常に類似しており、CCA類似スコアは> 0.9であり、内部ループが機能の変化をほとんどまたはまったく誘発しないことを示しています。対照的に、内部ループで大幅に変化するネットワークのヘッドは、CCAの類似性が0.5未満です。これをさらに検証するために、同じパターンを示す、ニューラルネットワーク表現の別の類似性メトリックであるCKA（Centered Kernel Alignment）（Kornblith et al。、2019）（図2右）も計算します。これらの代表的な分析結果は、機能の再利用の仮説を強く支持しており、付録のセクションB.3およびB.4でさらに多くの証拠が提供されています。

3.2.3 FEATURE REUSE HAPPENS EARLY IN LEARNING
3.2.3機能の再利用は学習の早い段階で行われます

Having observed that the inner loop does not significantly affect the learned representations with a fully trained model, we extend our analysis to see whether the inner loop affects representations and features earlier on in training. We take MAML models at 10000, 20000, and 30000 iterations into training, perform freezing experiments (as in Section 3.2.1) and representational similarity experiments (as in Section 3.2.2).
完全にトレーニングされたモデルでは、内側のループが学習された表現に大きな影響を与えないことを確認したので、分析を拡張して、トレーニングの早い段階で内側のループが表現と機能に影響を与えるかどうかを確認します。 10000、20000、および30000回の反復でMAMLモデルをトレーニングに取り入れ、凍結実験（セクション3.2.1のように）および表現類似性実験（セクション3.2.2のように）を実行します。
Results in Figure 3 show the same patterns from early in training, with CCA similarity between activations pre and post inner loop update on MiniImageNet-5way-5shot being very high for the body (just like Figure 2), and similar to Table 1, test accuracy remaining approximately the same when freezing contiguous subsets of layers, even when freezing all layers of the network body.
図3の結果は、トレーニングの初期からの同じパターンを示しています。MiniImageNet-5way-5shotの内部ループ更新前後のアクティベーション間のCCAの類似性は、体にとって非常に高く（図2と同様）、表1と同様です。ネットワーク本体のすべてのレイヤーをフリーズする場合でも、レイヤーの連続するサブセットをフリーズする場合でも、精度はほぼ同じままです。

This shows that even early on in training, significant feature reuse is taking place, with the inner loop having minimal effect on learned representations and features. Results for 1shot MiniImageNet are in Appendix B.5, and show very similar trends.
これは、トレーニングの早い段階でさえ、重要な機能の再利用が行われており、内部ループが学習された表現と機能に与える影響が最小限であることを示しています。 1shot MiniImageNetの結果は、付録B.5にあり、非常に類似した傾向を示しています。
