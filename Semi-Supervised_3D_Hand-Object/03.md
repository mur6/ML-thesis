3. Overview
Our method on 3D hand and object pose estimation con- tains two main components: (i) a joint learning framework with contextual reasoning between the hand and the object; (ii) a semi-supervised pipeline which explores extra labels in videos for training.
First, we present the hand-object joint learning framework in Section 4. The model contains a shared encoder and two separate decoders for hand and object, as well as a transformer-based contextual reasoning module 4.1 to better exploit their relations. The model is trained under fully- supervised learning.

Then, we propose the semi-supervised learning pipeline in Section 5, Constrained by the spatial-temporal consistency, we generate high-quality pseudo-labels of hand on a large- scale video dataset [18] and re-train our model on the union of fully annotated dataset [20] and those confident pseudo- labels. Because of the diversity in the hand pseudo-labels, the model could both increase the accuracy of hand pose estimation and generalization. With better hand features as context via the contextual reasoning module, the object pose performance of the model could also be improved.
